{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f441485c",
   "metadata": {},
   "source": [
    "# Introducing Machine Learning in Python with Scikit-learn\n",
    "\n",
    "## by Corey Wade\n",
    "\n",
    "The following Jupyter Notebook is an introduction to Machine Learning in Python designed for ODSC West attendees on Monday, October 30, 2023. We use pandas for preliminary data analytics, and sklearn for machine learning. A wide range of models will be covered including Linear and Logistic Regression, Decision Trees, Random Forests, XGBoost, and a version of LightGBM.\n",
    "\n",
    "This presentation includes an updated version of ML fundamentals as covered in Corey Wade's book [Hands-on Gradient Boosting with XGBoost and scikit-learn](https://www.amazon.com/Hands-Gradient-Boosting-XGBoost-scikit-learn/dp/1839218355).\n",
    "\n",
    "Our focus is on tabular data, that is, rows and columns of data sorted in tables, as contrasted with images and text which are considered unstructured data. When it comes to images and text, neural networks usually perform better. For tabular data, neural networks do not necessarily have an edge. We will focus on XGBoost, one the strongest ML algorithms in the world that has outperformed neural networks in Kaggle Competitions.\n",
    "\n",
    "Additional note: the regression and classification models presented fall under the umbrella of Supervised Learning, which means that the y-values of the target columns are known in advance. The other option is Unsupervised Learning where the target values are unknown; one example is taking the texts of books as input and grouping them into original genres.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ed5173",
   "metadata": {},
   "source": [
    "# Module 1 - Preparing data for ML with pandas\n",
    "\n",
    "This module provides a brief introduction to pandas in terms of preparing data for machine learning.\n",
    "\n",
    "For machine learning algorithms to work, all data must be numerical with no null values. This means that you can't have blanks in the data (null values) or words (categorical columns). Both must be converted into numbers for ML algorithms to work. Why? Because at the core, machine learning models are mathematical models and words or blanks will break them. \n",
    "\n",
    "For general information on pandas, visit the official documentation at https://pandas.pydata.org/docs/getting_started/tutorials.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad0d29",
   "metadata": {},
   "source": [
    "## 1.1 Loading Regression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f087aa",
   "metadata": {},
   "source": [
    "### Bike Rentals Dataset\n",
    "\n",
    "The [Bike Rentals dataset](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset) is from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php). It's been modified here to include correcting null values for practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdba1746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season   yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01     1.0  0.0   1.0      0.0      6.0         0.0   \n",
       "1        2  2011-01-02     1.0  0.0   1.0      0.0      0.0         0.0   \n",
       "2        3  2011-01-03     1.0  0.0   1.0      0.0      1.0         1.0   \n",
       "3        4  2011-01-04     1.0  0.0   1.0      0.0      2.0         1.0   \n",
       "4        5  2011-01-05     1.0  0.0   1.0      0.0      3.0         1.0   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data into pandas dataframe and show first 5 rows\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/coreyjwade/odsc/main/bike_rentals.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450dfe0",
   "metadata": {},
   "source": [
    "## 1.2 Accessing General Data Stats\n",
    "It's useful to see the data in terms of general statistics to better understand the data at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f32e417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>726.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>366.000000</td>\n",
       "      <td>2.496580</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.512329</td>\n",
       "      <td>0.028728</td>\n",
       "      <td>2.997264</td>\n",
       "      <td>0.682627</td>\n",
       "      <td>1.395349</td>\n",
       "      <td>0.495587</td>\n",
       "      <td>0.474512</td>\n",
       "      <td>0.627987</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>848.176471</td>\n",
       "      <td>3656.172367</td>\n",
       "      <td>4504.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>211.165812</td>\n",
       "      <td>1.110807</td>\n",
       "      <td>0.500343</td>\n",
       "      <td>3.448303</td>\n",
       "      <td>0.167155</td>\n",
       "      <td>2.004787</td>\n",
       "      <td>0.465773</td>\n",
       "      <td>0.544894</td>\n",
       "      <td>0.183094</td>\n",
       "      <td>0.163017</td>\n",
       "      <td>0.142331</td>\n",
       "      <td>0.077725</td>\n",
       "      <td>686.622488</td>\n",
       "      <td>1560.256377</td>\n",
       "      <td>1937.211452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059130</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022392</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>183.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336875</td>\n",
       "      <td>0.337794</td>\n",
       "      <td>0.521562</td>\n",
       "      <td>0.134494</td>\n",
       "      <td>315.500000</td>\n",
       "      <td>2497.000000</td>\n",
       "      <td>3152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>366.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499166</td>\n",
       "      <td>0.487364</td>\n",
       "      <td>0.627083</td>\n",
       "      <td>0.180971</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>3662.000000</td>\n",
       "      <td>4548.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>548.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.655625</td>\n",
       "      <td>0.608916</td>\n",
       "      <td>0.730104</td>\n",
       "      <td>0.233218</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>4776.500000</td>\n",
       "      <td>5956.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.861667</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>3410.000000</td>\n",
       "      <td>6946.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          instant      season          yr        mnth     holiday     weekday  \\\n",
       "count  731.000000  731.000000  730.000000  730.000000  731.000000  731.000000   \n",
       "mean   366.000000    2.496580    0.500000    6.512329    0.028728    2.997264   \n",
       "std    211.165812    1.110807    0.500343    3.448303    0.167155    2.004787   \n",
       "min      1.000000    1.000000    0.000000    1.000000    0.000000    0.000000   \n",
       "25%    183.500000    2.000000    0.000000    4.000000    0.000000    1.000000   \n",
       "50%    366.000000    3.000000    0.500000    7.000000    0.000000    3.000000   \n",
       "75%    548.500000    3.000000    1.000000    9.750000    0.000000    5.000000   \n",
       "max    731.000000    4.000000    1.000000   12.000000    1.000000    6.000000   \n",
       "\n",
       "       workingday  weathersit        temp       atemp         hum   windspeed  \\\n",
       "count  731.000000  731.000000  730.000000  730.000000  728.000000  726.000000   \n",
       "mean     0.682627    1.395349    0.495587    0.474512    0.627987    0.190476   \n",
       "std      0.465773    0.544894    0.183094    0.163017    0.142331    0.077725   \n",
       "min      0.000000    1.000000    0.059130    0.079070    0.000000    0.022392   \n",
       "25%      0.000000    1.000000    0.336875    0.337794    0.521562    0.134494   \n",
       "50%      1.000000    1.000000    0.499166    0.487364    0.627083    0.180971   \n",
       "75%      1.000000    2.000000    0.655625    0.608916    0.730104    0.233218   \n",
       "max      1.000000    3.000000    0.861667    0.840896    0.972500    0.507463   \n",
       "\n",
       "            casual   registered          cnt  \n",
       "count   731.000000   731.000000   731.000000  \n",
       "mean    848.176471  3656.172367  4504.348837  \n",
       "std     686.622488  1560.256377  1937.211452  \n",
       "min       2.000000    20.000000    22.000000  \n",
       "25%     315.500000  2497.000000  3152.000000  \n",
       "50%     713.000000  3662.000000  4548.000000  \n",
       "75%    1096.000000  4776.500000  5956.000000  \n",
       "max    3410.000000  6946.000000  8714.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show descriptive statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01115d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instant</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.122242e-01</td>\n",
       "      <td>8.660262e-01</td>\n",
       "      <td>0.494807</td>\n",
       "      <td>0.016145</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.009415</td>\n",
       "      <td>-0.021477</td>\n",
       "      <td>0.152677</td>\n",
       "      <td>0.154502</td>\n",
       "      <td>0.013773</td>\n",
       "      <td>-0.113047</td>\n",
       "      <td>0.275255</td>\n",
       "      <td>0.659623</td>\n",
       "      <td>0.628830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>0.412224</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-5.428568e-16</td>\n",
       "      <td>0.836863</td>\n",
       "      <td>-0.010537</td>\n",
       "      <td>-0.003080</td>\n",
       "      <td>0.016433</td>\n",
       "      <td>0.019211</td>\n",
       "      <td>0.336388</td>\n",
       "      <td>0.344739</td>\n",
       "      <td>0.209028</td>\n",
       "      <td>-0.228499</td>\n",
       "      <td>0.210399</td>\n",
       "      <td>0.411623</td>\n",
       "      <td>0.406100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr</th>\n",
       "      <td>0.866026</td>\n",
       "      <td>-5.428568e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.003975</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>-0.004103</td>\n",
       "      <td>-0.002945</td>\n",
       "      <td>-0.050322</td>\n",
       "      <td>0.050979</td>\n",
       "      <td>0.049350</td>\n",
       "      <td>-0.115456</td>\n",
       "      <td>-0.011963</td>\n",
       "      <td>0.249593</td>\n",
       "      <td>0.596168</td>\n",
       "      <td>0.568680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnth</th>\n",
       "      <td>0.494807</td>\n",
       "      <td>8.368628e-01</td>\n",
       "      <td>-3.975295e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>-0.007395</td>\n",
       "      <td>0.041218</td>\n",
       "      <td>0.226546</td>\n",
       "      <td>0.233626</td>\n",
       "      <td>0.227641</td>\n",
       "      <td>-0.206162</td>\n",
       "      <td>0.124549</td>\n",
       "      <td>0.296062</td>\n",
       "      <td>0.282624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>0.016145</td>\n",
       "      <td>-1.053666e-02</td>\n",
       "      <td>8.195345e-03</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.101960</td>\n",
       "      <td>-0.252224</td>\n",
       "      <td>-0.034627</td>\n",
       "      <td>-0.028759</td>\n",
       "      <td>-0.032685</td>\n",
       "      <td>-0.016095</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>0.054274</td>\n",
       "      <td>-0.108745</td>\n",
       "      <td>-0.068348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-3.079881e-03</td>\n",
       "      <td>-4.102570e-03</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>-0.101960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038678</td>\n",
       "      <td>0.031087</td>\n",
       "      <td>-0.001830</td>\n",
       "      <td>-0.009003</td>\n",
       "      <td>-0.052728</td>\n",
       "      <td>0.014384</td>\n",
       "      <td>0.059923</td>\n",
       "      <td>0.057367</td>\n",
       "      <td>0.067443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workingday</th>\n",
       "      <td>-0.009415</td>\n",
       "      <td>1.643296e-02</td>\n",
       "      <td>-2.945396e-03</td>\n",
       "      <td>-0.007395</td>\n",
       "      <td>-0.252224</td>\n",
       "      <td>0.038678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057866</td>\n",
       "      <td>0.055573</td>\n",
       "      <td>0.055329</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>-0.017720</td>\n",
       "      <td>-0.515692</td>\n",
       "      <td>0.306130</td>\n",
       "      <td>0.063781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weathersit</th>\n",
       "      <td>-0.021477</td>\n",
       "      <td>1.921103e-02</td>\n",
       "      <td>-5.032247e-02</td>\n",
       "      <td>0.041218</td>\n",
       "      <td>-0.034627</td>\n",
       "      <td>0.031087</td>\n",
       "      <td>0.057866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.119527</td>\n",
       "      <td>-0.120651</td>\n",
       "      <td>0.592841</td>\n",
       "      <td>0.038912</td>\n",
       "      <td>-0.247353</td>\n",
       "      <td>-0.260388</td>\n",
       "      <td>-0.297391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>0.152677</td>\n",
       "      <td>3.363881e-01</td>\n",
       "      <td>5.097873e-02</td>\n",
       "      <td>0.226546</td>\n",
       "      <td>-0.028759</td>\n",
       "      <td>-0.001830</td>\n",
       "      <td>0.055573</td>\n",
       "      <td>-0.119527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991702</td>\n",
       "      <td>0.133380</td>\n",
       "      <td>-0.159242</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>0.540327</td>\n",
       "      <td>0.627860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atemp</th>\n",
       "      <td>0.154502</td>\n",
       "      <td>3.447388e-01</td>\n",
       "      <td>4.934973e-02</td>\n",
       "      <td>0.233626</td>\n",
       "      <td>-0.032685</td>\n",
       "      <td>-0.009003</td>\n",
       "      <td>0.055329</td>\n",
       "      <td>-0.120651</td>\n",
       "      <td>0.991702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.146036</td>\n",
       "      <td>-0.184754</td>\n",
       "      <td>0.544113</td>\n",
       "      <td>0.544442</td>\n",
       "      <td>0.631357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hum</th>\n",
       "      <td>0.013773</td>\n",
       "      <td>2.090284e-01</td>\n",
       "      <td>-1.154557e-01</td>\n",
       "      <td>0.227641</td>\n",
       "      <td>-0.016095</td>\n",
       "      <td>-0.052728</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.592841</td>\n",
       "      <td>0.133380</td>\n",
       "      <td>0.146036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.251193</td>\n",
       "      <td>-0.076438</td>\n",
       "      <td>-0.090947</td>\n",
       "      <td>-0.100330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>-0.113047</td>\n",
       "      <td>-2.284989e-01</td>\n",
       "      <td>-1.196259e-02</td>\n",
       "      <td>-0.206162</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>0.014384</td>\n",
       "      <td>-0.017720</td>\n",
       "      <td>0.038912</td>\n",
       "      <td>-0.159242</td>\n",
       "      <td>-0.184754</td>\n",
       "      <td>-0.251193</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.167568</td>\n",
       "      <td>-0.217596</td>\n",
       "      <td>-0.234704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casual</th>\n",
       "      <td>0.275255</td>\n",
       "      <td>2.103992e-01</td>\n",
       "      <td>2.495927e-01</td>\n",
       "      <td>0.124549</td>\n",
       "      <td>0.054274</td>\n",
       "      <td>0.059923</td>\n",
       "      <td>-0.515692</td>\n",
       "      <td>-0.247353</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>0.544113</td>\n",
       "      <td>-0.076438</td>\n",
       "      <td>-0.167568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.395282</td>\n",
       "      <td>0.672804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>registered</th>\n",
       "      <td>0.659623</td>\n",
       "      <td>4.116231e-01</td>\n",
       "      <td>5.961675e-01</td>\n",
       "      <td>0.296062</td>\n",
       "      <td>-0.108745</td>\n",
       "      <td>0.057367</td>\n",
       "      <td>0.306130</td>\n",
       "      <td>-0.260388</td>\n",
       "      <td>0.540327</td>\n",
       "      <td>0.544442</td>\n",
       "      <td>-0.090947</td>\n",
       "      <td>-0.217596</td>\n",
       "      <td>0.395282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnt</th>\n",
       "      <td>0.628830</td>\n",
       "      <td>4.061004e-01</td>\n",
       "      <td>5.686803e-01</td>\n",
       "      <td>0.282624</td>\n",
       "      <td>-0.068348</td>\n",
       "      <td>0.067443</td>\n",
       "      <td>0.063781</td>\n",
       "      <td>-0.297391</td>\n",
       "      <td>0.627860</td>\n",
       "      <td>0.631357</td>\n",
       "      <td>-0.100330</td>\n",
       "      <td>-0.234704</td>\n",
       "      <td>0.672804</td>\n",
       "      <td>0.945517</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             instant        season            yr      mnth   holiday  \\\n",
       "instant     1.000000  4.122242e-01  8.660262e-01  0.494807  0.016145   \n",
       "season      0.412224  1.000000e+00 -5.428568e-16  0.836863 -0.010537   \n",
       "yr          0.866026 -5.428568e-16  1.000000e+00 -0.003975  0.008195   \n",
       "mnth        0.494807  8.368628e-01 -3.975295e-03  1.000000  0.019599   \n",
       "holiday     0.016145 -1.053666e-02  8.195345e-03  0.019599  1.000000   \n",
       "weekday    -0.000016 -3.079881e-03 -4.102570e-03  0.011707 -0.101960   \n",
       "workingday -0.009415  1.643296e-02 -2.945396e-03 -0.007395 -0.252224   \n",
       "weathersit -0.021477  1.921103e-02 -5.032247e-02  0.041218 -0.034627   \n",
       "temp        0.152677  3.363881e-01  5.097873e-02  0.226546 -0.028759   \n",
       "atemp       0.154502  3.447388e-01  4.934973e-02  0.233626 -0.032685   \n",
       "hum         0.013773  2.090284e-01 -1.154557e-01  0.227641 -0.016095   \n",
       "windspeed  -0.113047 -2.284989e-01 -1.196259e-02 -0.206162  0.006319   \n",
       "casual      0.275255  2.103992e-01  2.495927e-01  0.124549  0.054274   \n",
       "registered  0.659623  4.116231e-01  5.961675e-01  0.296062 -0.108745   \n",
       "cnt         0.628830  4.061004e-01  5.686803e-01  0.282624 -0.068348   \n",
       "\n",
       "             weekday  workingday  weathersit      temp     atemp       hum  \\\n",
       "instant    -0.000016   -0.009415   -0.021477  0.152677  0.154502  0.013773   \n",
       "season     -0.003080    0.016433    0.019211  0.336388  0.344739  0.209028   \n",
       "yr         -0.004103   -0.002945   -0.050322  0.050979  0.049350 -0.115456   \n",
       "mnth        0.011707   -0.007395    0.041218  0.226546  0.233626  0.227641   \n",
       "holiday    -0.101960   -0.252224   -0.034627 -0.028759 -0.032685 -0.016095   \n",
       "weekday     1.000000    0.038678    0.031087 -0.001830 -0.009003 -0.052728   \n",
       "workingday  0.038678    1.000000    0.057866  0.055573  0.055329  0.025879   \n",
       "weathersit  0.031087    0.057866    1.000000 -0.119527 -0.120651  0.592841   \n",
       "temp       -0.001830    0.055573   -0.119527  1.000000  0.991702  0.133380   \n",
       "atemp      -0.009003    0.055329   -0.120651  0.991702  1.000000  0.146036   \n",
       "hum        -0.052728    0.025879    0.592841  0.133380  0.146036  1.000000   \n",
       "windspeed   0.014384   -0.017720    0.038912 -0.159242 -0.184754 -0.251193   \n",
       "casual      0.059923   -0.515692   -0.247353  0.543600  0.544113 -0.076438   \n",
       "registered  0.057367    0.306130   -0.260388  0.540327  0.544442 -0.090947   \n",
       "cnt         0.067443    0.063781   -0.297391  0.627860  0.631357 -0.100330   \n",
       "\n",
       "            windspeed    casual  registered       cnt  \n",
       "instant     -0.113047  0.275255    0.659623  0.628830  \n",
       "season      -0.228499  0.210399    0.411623  0.406100  \n",
       "yr          -0.011963  0.249593    0.596168  0.568680  \n",
       "mnth        -0.206162  0.124549    0.296062  0.282624  \n",
       "holiday      0.006319  0.054274   -0.108745 -0.068348  \n",
       "weekday      0.014384  0.059923    0.057367  0.067443  \n",
       "workingday  -0.017720 -0.515692    0.306130  0.063781  \n",
       "weathersit   0.038912 -0.247353   -0.260388 -0.297391  \n",
       "temp        -0.159242  0.543600    0.540327  0.627860  \n",
       "atemp       -0.184754  0.544113    0.544442  0.631357  \n",
       "hum         -0.251193 -0.076438   -0.090947 -0.100330  \n",
       "windspeed    1.000000 -0.167568   -0.217596 -0.234704  \n",
       "casual      -0.167568  1.000000    0.395282  0.672804  \n",
       "registered  -0.217596  0.395282    1.000000  0.945517  \n",
       "cnt         -0.234704  0.672804    0.945517  1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show correlations between columns\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5234c5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731 entries, 0 to 730\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   instant     731 non-null    int64  \n",
      " 1   dteday      731 non-null    object \n",
      " 2   season      731 non-null    float64\n",
      " 3   yr          730 non-null    float64\n",
      " 4   mnth        730 non-null    float64\n",
      " 5   holiday     731 non-null    float64\n",
      " 6   weekday     731 non-null    float64\n",
      " 7   workingday  731 non-null    float64\n",
      " 8   weathersit  731 non-null    int64  \n",
      " 9   temp        730 non-null    float64\n",
      " 10  atemp       730 non-null    float64\n",
      " 11  hum         728 non-null    float64\n",
      " 12  windspeed   726 non-null    float64\n",
      " 13  casual      731 non-null    int64  \n",
      " 14  registered  731 non-null    int64  \n",
      " 15  cnt         731 non-null    int64  \n",
      "dtypes: float64(10), int64(5), object(1)\n",
      "memory usage: 91.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# get info on columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522f45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show histograms and scatter plots of all columns\n",
    "import seaborn as sns\n",
    "#sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a891761b",
   "metadata": {},
   "source": [
    "## 1.3 Correcting Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1d651",
   "metadata": {},
   "source": [
    "Machine learning algorithms are like mathematical models. For the algorithms to work, all inputs must have values. Null values will break the algorithm. We need to find the null values in our data and change them.\n",
    "\n",
    "You can eliminate columns if they are almost all null values, or eliminate rows if they have too many null values. However, if the rows and columns contain other valuable information it's often better to keep them and to change the null values to a statistical average of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4325a580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0\n",
       "dteday        0\n",
       "season        0\n",
       "yr            1\n",
       "mnth          1\n",
       "holiday       0\n",
       "weekday       0\n",
       "workingday    0\n",
       "weathersit    0\n",
       "temp          1\n",
       "atemp         1\n",
       "hum           3\n",
       "windspeed     5\n",
       "casual        0\n",
       "registered    0\n",
       "cnt           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show total null values per column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b3b069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum null values\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04c5e869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>2011-02-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.282192</td>\n",
       "      <td>0.537917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>424</td>\n",
       "      <td>1545</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>2011-03-23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.346957</td>\n",
       "      <td>0.337939</td>\n",
       "      <td>0.839565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203</td>\n",
       "      <td>1918</td>\n",
       "      <td>2121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>2011-05-09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532500</td>\n",
       "      <td>0.525246</td>\n",
       "      <td>0.588750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>664</td>\n",
       "      <td>3698</td>\n",
       "      <td>4362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>130</td>\n",
       "      <td>2011-05-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532500</td>\n",
       "      <td>0.522721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115671</td>\n",
       "      <td>694</td>\n",
       "      <td>4109</td>\n",
       "      <td>4803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214</td>\n",
       "      <td>2011-08-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.205850</td>\n",
       "      <td>801</td>\n",
       "      <td>4044</td>\n",
       "      <td>4845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>2011-10-26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.484167</td>\n",
       "      <td>0.472846</td>\n",
       "      <td>0.720417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>404</td>\n",
       "      <td>3490</td>\n",
       "      <td>3894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>389</td>\n",
       "      <td>2012-01-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.349108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123767</td>\n",
       "      <td>439</td>\n",
       "      <td>3900</td>\n",
       "      <td>4339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>529</td>\n",
       "      <td>2012-06-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.597875</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>477</td>\n",
       "      <td>4495</td>\n",
       "      <td>4972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>702</td>\n",
       "      <td>2012-12-02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>0.124379</td>\n",
       "      <td>892</td>\n",
       "      <td>3757</td>\n",
       "      <td>4649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season   yr  mnth  holiday  weekday  workingday  \\\n",
       "56        57  2011-02-26     1.0  0.0   2.0      0.0      6.0         0.0   \n",
       "81        82  2011-03-23     2.0  0.0   3.0      0.0      3.0         1.0   \n",
       "128      129  2011-05-09     2.0  0.0   5.0      0.0      1.0         1.0   \n",
       "129      130  2011-05-10     2.0  0.0   5.0      0.0      2.0         1.0   \n",
       "213      214  2011-08-02     3.0  0.0   8.0      0.0      2.0         1.0   \n",
       "298      299  2011-10-26     4.0  0.0  10.0      0.0      3.0         1.0   \n",
       "388      389  2012-01-24     1.0  1.0   1.0      0.0      2.0         1.0   \n",
       "528      529  2012-06-12     2.0  1.0   6.0      0.0      2.0         1.0   \n",
       "701      702  2012-12-02     4.0  1.0  12.0      0.0      0.0         0.0   \n",
       "730      731  2012-12-31     1.0  NaN   NaN      0.0      1.0         0.0   \n",
       "\n",
       "     weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "56            1  0.282500  0.282192  0.537917        NaN     424        1545   \n",
       "81            2  0.346957  0.337939  0.839565        NaN     203        1918   \n",
       "128           1  0.532500  0.525246  0.588750        NaN     664        3698   \n",
       "129           1  0.532500  0.522721       NaN   0.115671     694        4109   \n",
       "213           1  0.783333  0.707071       NaN   0.205850     801        4044   \n",
       "298           2  0.484167  0.472846  0.720417        NaN     404        3490   \n",
       "388           1  0.342500  0.349108       NaN   0.123767     439        3900   \n",
       "528           2  0.653333  0.597875  0.833333        NaN     477        4495   \n",
       "701           2       NaN       NaN  0.823333   0.124379     892        3757   \n",
       "730           2  0.215833  0.223487  0.577500   0.154846     439        2290   \n",
       "\n",
       "      cnt  \n",
       "56   1969  \n",
       "81   2121  \n",
       "128  4362  \n",
       "129  4803  \n",
       "213  4845  \n",
       "298  3894  \n",
       "388  4339  \n",
       "528  4972  \n",
       "701  4649  \n",
       "730  2729  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows all null values by row\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c86e37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change null values in column to median of column\n",
    "df['windspeed'] = df['windspeed'].fillna(df['windspeed'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4859dd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>2011-02-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.282192</td>\n",
       "      <td>0.537917</td>\n",
       "      <td>0.180971</td>\n",
       "      <td>424</td>\n",
       "      <td>1545</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>2011-03-23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.346957</td>\n",
       "      <td>0.337939</td>\n",
       "      <td>0.839565</td>\n",
       "      <td>0.180971</td>\n",
       "      <td>203</td>\n",
       "      <td>1918</td>\n",
       "      <td>2121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>2011-05-09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532500</td>\n",
       "      <td>0.525246</td>\n",
       "      <td>0.588750</td>\n",
       "      <td>0.180971</td>\n",
       "      <td>664</td>\n",
       "      <td>3698</td>\n",
       "      <td>4362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season   yr  mnth  holiday  weekday  workingday  \\\n",
       "56        57  2011-02-26     1.0  0.0   2.0      0.0      6.0         0.0   \n",
       "81        82  2011-03-23     2.0  0.0   3.0      0.0      3.0         1.0   \n",
       "128      129  2011-05-09     2.0  0.0   5.0      0.0      1.0         1.0   \n",
       "\n",
       "     weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "56            1  0.282500  0.282192  0.537917   0.180971     424        1545   \n",
       "81            2  0.346957  0.337939  0.839565   0.180971     203        1918   \n",
       "128           1  0.532500  0.525246  0.588750   0.180971     664        3698   \n",
       "\n",
       "      cnt  \n",
       "56   1969  \n",
       "81   2121  \n",
       "128  4362  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show rows of changed data\n",
    "df.iloc[[56,81,128]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc172cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>364</td>\n",
       "      <td>1432</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season   yr  mnth  holiday  weekday  workingday  \\\n",
       "729      730  2012-12-30     1.0  1.0  12.0      0.0      0.0         0.0   \n",
       "730      731  2012-12-31     1.0  NaN   NaN      0.0      1.0         0.0   \n",
       "\n",
       "     weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "729           1  0.255833  0.231700  0.483333   0.350754     364        1432   \n",
       "730           2  0.215833  0.223487  0.577500   0.154846     439        2290   \n",
       "\n",
       "      cnt  \n",
       "729  1796  \n",
       "730  2729  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show last row of data\n",
    "df.loc[[729, 730]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58a2bce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season   yr  mnth  holiday  weekday  workingday  \\\n",
       "730      731  2012-12-31     1.0  1.0  12.0      0.0      1.0         0.0   \n",
       "\n",
       "     weathersit      temp     atemp     hum  windspeed  casual  registered  \\\n",
       "730           2  0.215833  0.223487  0.5775   0.154846     439        2290   \n",
       "\n",
       "      cnt  \n",
       "730  2729  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change null values by entry\n",
    "df.loc[730,'yr']=1.0\n",
    "df.loc[730, 'mnth']=12.0\n",
    "\n",
    "# show changed data\n",
    "df.loc[[730]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a0461ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change null values for entire dataframe\n",
    "df = df.fillna(df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6666ebc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that all null values have been corrected\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d621d92",
   "metadata": {},
   "source": [
    "## 1.4 Loading Classification Data\n",
    "\n",
    "### Census Dataset\n",
    "\n",
    "The [Census Dataset](https://archive.ics.uci.edu/ml/datasets/Adult) (also called the Adult Dataset) is also from UCI. We include this dataset to balance regression with classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52b357eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload Census dataset with no header (none is provided - prevents first row of data as header)\n",
    "df2 = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header=None)\n",
    "\n",
    "# define columns by name\n",
    "df2.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
    "                  'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   'income']\n",
    "\n",
    "# show first 5 rows\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da7681",
   "metadata": {},
   "source": [
    "The issue with this dataset is that we have many categorical (text) columns. We need to turn these columns into numerical columns to make progress. Remember, since ML algorithms are like mathematical models, they need to have numbers as their inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9036e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# get column info\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec29971e",
   "metadata": {},
   "source": [
    "Note that objects are usually strings. The dtype is an object which serves as a pointer to preserve size and speed (see https://stackoverflow.com/questions/21018654/strings-in-a-dataframe-but-dtype-is-object for a discussion as to why.)\n",
    "\n",
    "We need to convert the string columns into numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18153e6c",
   "metadata": {},
   "source": [
    "## 1.5 One-hot encoding\n",
    "\n",
    "One-hot encoding means you take each categorical column (say Color), and transform it into new columns for each value (Red, Green, Blue) as the new column header; the new columns values are 1 for presence, and 0 for absence. pd.get_dummies() often works for this purpose. sklearn includes an additional [onehotencoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) that works well in pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b214c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pd.get_dummies() to transform categorical into numerical columns\n",
    "df2 = pd.get_dummies(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "920550e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "      <th>income_ &lt;=50K</th>\n",
       "      <th>income_ &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0             0                       0                     0   \n",
       "1             0                       0                     0   \n",
       "2             0                       0                     0   \n",
       "3             0                       0                     0   \n",
       "4             0                       0                     0   \n",
       "\n",
       "   workclass_ Never-worked  ...  native-country_ Scotland  \\\n",
       "0                        0  ...                         0   \n",
       "1                        0  ...                         0   \n",
       "2                        0  ...                         0   \n",
       "3                        0  ...                         0   \n",
       "4                        0  ...                         0   \n",
       "\n",
       "   native-country_ South  native-country_ Taiwan  native-country_ Thailand  \\\n",
       "0                      0                       0                         0   \n",
       "1                      0                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       0                         0   \n",
       "4                      0                       0                         0   \n",
       "\n",
       "   native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "0                                0                              1   \n",
       "1                                0                              1   \n",
       "2                                0                              1   \n",
       "3                                0                              1   \n",
       "4                                0                              0   \n",
       "\n",
       "   native-country_ Vietnam  native-country_ Yugoslavia  income_ <=50K  \\\n",
       "0                        0                           0              1   \n",
       "1                        0                           0              1   \n",
       "2                        0                           0              1   \n",
       "3                        0                           0              1   \n",
       "4                        0                           0              1   \n",
       "\n",
       "   income_ >50K  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show df after one-hot-encoding\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f84224c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Columns: 110 entries, age to income_ >50K\n",
      "dtypes: int64(6), uint8(104)\n",
      "memory usage: 4.7 MB\n"
     ]
    }
   ],
   "source": [
    "# get new number of columns\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05733e4",
   "metadata": {},
   "source": [
    "# Module 2 -  Building your first ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a27dab",
   "metadata": {},
   "source": [
    "Now that the data is all numerical with no null-values, we can build a machine learning Model. An ML model takes a range of columns, the X-values, as the input, and one column, the y-value as the output. The model itself will be a mathematical model that tries to match the inputs with the outputs. This is challenging because there are many rows of data and all need to be matched."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f27a0",
   "metadata": {},
   "source": [
    "## 2.1 Choosing X and y\n",
    "\n",
    "The y-column is what you are trying to predict. It's what you want to know about the future. It's the column that you want to predict from the other columns.\n",
    "\n",
    "The X-columns are the data that you already have. It's what you already know. It's what you will use to predict the future.\n",
    "\n",
    "There is no right or wrong in terms of choosing  X (uppercase to denote many), and y (lowercase to denote one). It's all about your data and the problem that you are trying to solve. Machine learning's primary use-case is in solving problems about the future, that is, in using data that you have to predict what you want to know. \n",
    "\n",
    "Machine learning models are trained, however, on data in which the future is known, data in which you already have the y-values to match the X-values. You need this for machine learning models to learn. This is why it's called machine learning. The models learn their parameters from data that you already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "107a810d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season   yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01     1.0  0.0   1.0      0.0      6.0         0.0   \n",
       "1        2  2011-01-02     1.0  0.0   1.0      0.0      0.0         0.0   \n",
       "2        3  2011-01-03     1.0  0.0   1.0      0.0      1.0         1.0   \n",
       "3        4  2011-01-04     1.0  0.0   1.0      0.0      2.0         1.0   \n",
       "4        5  2011-01-05     1.0  0.0   1.0      0.0      3.0         1.0   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all the data before choosing X and y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c96c3555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season   yr  mnth  holiday  weekday  workingday  weathersit      temp  \\\n",
       "0     1.0  0.0   1.0      0.0      6.0         0.0           2  0.344167   \n",
       "1     1.0  0.0   1.0      0.0      0.0         0.0           2  0.363478   \n",
       "2     1.0  0.0   1.0      0.0      1.0         1.0           1  0.196364   \n",
       "3     1.0  0.0   1.0      0.0      2.0         1.0           1  0.200000   \n",
       "4     1.0  0.0   1.0      0.0      3.0         1.0           1  0.226957   \n",
       "\n",
       "      atemp       hum  windspeed  \n",
       "0  0.363625  0.805833   0.160446  \n",
       "1  0.353739  0.696087   0.248539  \n",
       "2  0.189405  0.437273   0.248309  \n",
       "3  0.212122  0.590435   0.160296  \n",
       "4  0.229270  0.436957   0.186900  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose X as all columns excluding the first 2, and last 3\n",
    "X = df.iloc[:, 2:-3]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ddecf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     985\n",
       "1     801\n",
       "2    1349\n",
       "3    1562\n",
       "4    1600\n",
       "Name: cnt, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose y as the last column\n",
    "y=df.iloc[:, -1]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dc0d888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "      <th>income_ &lt;=50K</th>\n",
       "      <th>income_ &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0             0                       0                     0   \n",
       "1             0                       0                     0   \n",
       "2             0                       0                     0   \n",
       "3             0                       0                     0   \n",
       "4             0                       0                     0   \n",
       "\n",
       "   workclass_ Never-worked  ...  native-country_ Scotland  \\\n",
       "0                        0  ...                         0   \n",
       "1                        0  ...                         0   \n",
       "2                        0  ...                         0   \n",
       "3                        0  ...                         0   \n",
       "4                        0  ...                         0   \n",
       "\n",
       "   native-country_ South  native-country_ Taiwan  native-country_ Thailand  \\\n",
       "0                      0                       0                         0   \n",
       "1                      0                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       0                         0   \n",
       "4                      0                       0                         0   \n",
       "\n",
       "   native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "0                                0                              1   \n",
       "1                                0                              1   \n",
       "2                                0                              1   \n",
       "3                                0                              1   \n",
       "4                                0                              0   \n",
       "\n",
       "   native-country_ Vietnam  native-country_ Yugoslavia  income_ <=50K  \\\n",
       "0                        0                           0              1   \n",
       "1                        0                           0              1   \n",
       "2                        0                           0              1   \n",
       "3                        0                           0              1   \n",
       "4                        0                           0              1   \n",
       "\n",
       "   income_ >50K  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show census column data\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1e862ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select X as starting with second column, columns except for last 2\n",
    "X2 = df2.iloc[:, :-2]\n",
    "\n",
    "# select y as last column\n",
    "y2 = df2.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21586bc6",
   "metadata": {},
   "source": [
    "## 2.2 Splitting Data into Training and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e420d",
   "metadata": {},
   "source": [
    "It's standard to split the data into a training and a test set. The idea is to keep some of the data back to test the model that you build. That way, after building a model on the training set, you can see how well your model performs on data that it has never seen before.\n",
    "\n",
    "Splitting the data is important because it helps to prevent models from overfitting. Overfitting is when your model follows the original data too closely, picking up on possible errors and outliers. You want your ML model to generalize well to new data. You don't want it to over-focus on fluctuations within the sample data at hand. This is called finding a blance between variance and bias in the literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcd088f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d5561",
   "metadata": {},
   "source": [
    "## 2.3 Linear Regression\n",
    "\n",
    "Linear Regression is an ML model that tries to fit the data onto a straight line in 2D, or a hyperplane in higher dimensions. The goal is to find the best weights, or multipliers, for each column in X, that when summed together are as close as possible to y. \n",
    "\n",
    "Initially the chosen weights are random, and the model is scored. The weights are then adjusted depending on whether the score is too high or too low using gradient descent. Each time the weights are adjusted a new score results. The model continues adjusting until it converges to optimize the score.\n",
    "\n",
    "Linear Regression can be useful if the data is actually linear, otherwise nonlinear models like trees will perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95388c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8043199228256777"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# initialize model\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit model to training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# score model on test data (uses r2 default metric)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808413f1",
   "metadata": {},
   "source": [
    "## 2.4 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8a850c",
   "metadata": {},
   "source": [
    "Logistic Regression follows the same steps as Linear Regression except for the final step in which it transforms the y-value after the columns are multiplied and summed by placing it in the sigmoid equation (1/(1+e^-y) before converting it to an of 1 if the value is greater than 0.5, and 0 otherwise. \n",
    "\n",
    "See https://en.wikipedia.org/wiki/Sigmoid_function for more details on the Sigmoid.\n",
    "\n",
    "Note that Logistic Regression is used for datasets that require classification, and not regression. (Regression as a category of ML models and regression as generally used in statistics often overlap but the terms diverge here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66cdea5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7930293259634577"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# initialize model\n",
    "model2 = LogisticRegression()\n",
    "\n",
    "# fit model to training data\n",
    "model2.fit(X2_train, y2_train)\n",
    "\n",
    "# score model on test data (uses r2 default metric)\n",
    "model2.score(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f19333",
   "metadata": {},
   "source": [
    "## 2.5 Model Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f750c",
   "metadata": {},
   "source": [
    "After the models are built, additional information may be extracted such as the coefficients (the weights), and the parameters that were used (defaults in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d12ef22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  463.28677223,  1968.80524346,   -30.32533849,  -369.28610848,\n",
       "          74.59482084,    79.66752654,  -521.62688875,  2612.11138052,\n",
       "        3076.78720844, -1332.29012748, -2864.90698442])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show model coefficients\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a86f2857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'n_jobs': None,\n",
       " 'normalize': False,\n",
       " 'positive': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show model params\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e8da2",
   "metadata": {},
   "source": [
    "## 2.6 Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cad523",
   "metadata": {},
   "source": [
    "The most valuable part of machine learning models are the predictions that it can make. Models have a method, .predict, that can be used to make predictions provided that the input is in the same format as the data that the model was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6095c782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show model predictions for last 5 rows\n",
    "model2.predict(X2_test.iloc[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e86cd7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7694     1\n",
       "10410    0\n",
       "1043     1\n",
       "30860    0\n",
       "12467    1\n",
       "Name: income_ >50K, dtype: uint8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare predictions to actual results\n",
    "y2_test[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb7fa237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43843834, 0.56156166],\n",
       "       [0.7915125 , 0.2084875 ],\n",
       "       [0.22969899, 0.77030101],\n",
       "       [0.67225282, 0.32774718],\n",
       "       [0.76947398, 0.23052602]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can even get the probabilities of the predictions\n",
    "model2.predict_proba(X2_test.iloc[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f76e33",
   "metadata": {},
   "source": [
    "We have column headers included in the training set. The training data may be converted to numpy arrays to avoid column headers as will be shown later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7148362f",
   "metadata": {},
   "source": [
    "## 2.7 Other Regressors\n",
    "\n",
    "Sklearn provides many other regressors that may be tried on a regression dataset, which is when y has a range of numerical values and the models are trying to get as close as possible to those values. We try a sample of tree-based models and ensembles underneath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c283f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to score regressors\n",
    "def score_reg(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2754eb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7904487022264318"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and score Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "score_reg(DecisionTreeRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e85a76fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9008983119788628"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and score Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "score_reg(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f10c113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/coreyjwade/opt/anaconda3/lib/python3.8/site-packages (1.6.2)\n",
      "Requirement already satisfied: numpy in /Users/coreyjwade/opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in /Users/coreyjwade/opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.6.2)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# install XGBoost to your computer\n",
    "import sys\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0b4b3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8875910428315762"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and score XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "score_reg(XGBRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6040640e",
   "metadata": {},
   "source": [
    "## 2.8 Other Classifiers\n",
    "Many ML algorithms have their own versions of classification and regression. Here are the classification versions of some tree-based models and ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67da76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function to score classifiers\n",
    "def score_clf(model):\n",
    "    model.fit(X2_train, y2_train)\n",
    "    return model.score(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6c30c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136035621065562"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and score Decision Tree for classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "score_clf(DecisionTreeClassifier(random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbb4f0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8484569322892677"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and score Random Forest for classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "score_clf(RandomForestClassifier(random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df9cbf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.869031168432366"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and score XGBoost for classification\n",
    "from xgboost import XGBClassifier\n",
    "score_clf(XGBClassifier(random_state=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f788f",
   "metadata": {},
   "source": [
    "# Module 3 - Cross-validation with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ef282",
   "metadata": {},
   "source": [
    "Cross-validation is a general technique for splitting your data into multiple training and validation sets. By using cross-validation, your ML models will generalize better since they are scored against multiple validation sets, instead of just one.\n",
    "\n",
    "We now distinguish between validation sets and test sets. A validation set is what we use to validate models that we are trying out. We can change the models, and validate them by scoring them on the validation set. The test set, by contrast, is held back until the very end after our best model has been finalized. Think of a validation set as a test set while you still selecting and tuning models, and the test set as the final word to verify that your model generalizes well.\n",
    "\n",
    "[Here is a visual example of cross-validation.](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#/media/File:K-fold_cross_validation_EN.svg) Split your training set into 5 evenly split folds. Hold the first fold back as a validation set, then train your model on the remaining four folds of data before scoring it on the validation set. Next, take the second fold of data and hold it back as the validation set, training your model on the remaining four folds before scoring it on the validation set. Continue the process for all 5 folds of the data.\n",
    "\n",
    "Cross-validation works for n folds where n is commonly 3,5,10 or 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b412e",
   "metadata": {},
   "source": [
    "## 3.1 Cross_val_score\n",
    "Cross_val_score in sklearn is a great way to score models using cross-validation as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9a009b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86032332 0.79450923 0.84489855 0.82828609 0.89426178]\n",
      "0.8444557932746213\n"
     ]
    }
   ],
   "source": [
    "# import cross_val_score to use cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# choose your model\n",
    "model=XGBRegressor()\n",
    "# get scores on five folds of data \n",
    "scores = cross_val_score(model, X_train, y_train, scoring='r2', cv=5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afadb15",
   "metadata": {},
   "source": [
    "## 3.2 Kfold cross-validation\n",
    "Kfold cross-validation allows for balanced, consistent splits that may also be applied to grid searches and randomized searches as in the next module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "199edbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84248305 0.8942442  0.877875   0.88271032 0.86781641]\n",
      "0.8730257979482665\n"
     ]
    }
   ],
   "source": [
    "# use KFold for shuffled, consistent folds \n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "model=XGBRegressor()\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='r2', cv=kfold)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62577d3a",
   "metadata": {},
   "source": [
    "## 3.3 Stratified Kfold Cross-Validation\n",
    "Stratified Kfold is used to ensure that classification datasets have the same number of positive cases (or categories) in the different validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2977fd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86933825 0.87177518 0.872543   0.86916462 0.87392506]\n",
      "0.8713492217983237\n"
     ]
    }
   ],
   "source": [
    "# use stratified Kfold for classification to balance all test sets\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "ksfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "clf=XGBClassifier()\n",
    "scores = cross_val_score(clf, X2, y2, scoring='accuracy', cv=ksfold)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7afa1bb",
   "metadata": {},
   "source": [
    "## 3.4 Choosing Scoring Metrics\n",
    "\n",
    "There are [many scoring metrics available in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html), especially for classification. Though Accuray and R2 are sklearn defaults, it's common to use other scoring metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc62999",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error\n",
    "It's standard to choose the RMSE (root mean squared error) as your scoring metric in regression which tells you how far away your predictions are from the actual value. To implement this, you must select the negative mean squared error metric, and then take the negative square root. (In sklearn this keeps scoring metrics as \"the higher the better;\" for RMSE lower is better, hence the negative.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb9bf3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[694.52090903 683.65580679 672.00913665 649.07556961 652.47237418]\n",
      "670.3467592511886\n"
     ]
    }
   ],
   "source": [
    "# change scoring to RMSE \n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "model=XGBRegressor()\n",
    "mse = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=kfold)\n",
    "rmse = (-mse)**0.5\n",
    "print(rmse)\n",
    "print(rmse.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba90710e",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d3c33",
   "metadata": {},
   "source": [
    "The Confusion Matrix and Classification Report show how predictions work in terms of precision, recall and the f1-score which is their harmonic balance.\n",
    "\n",
    "Accuracy is often not good enough as a scoring metric. If you have imbalanced data, say only 0.1 percent exoplanets, your model can be 99.9 percent accurate if it predicts no exoplanets. Awesome score, and you have learned nothing. \n",
    "\n",
    "If you want to publish results about exoplanets, you likely care more about precision, which is the percentage that your positive results, the exoplanets, are actually exoplanets without concern about incorrect negatives.\n",
    "\n",
    "Recall might be useful if you want to conduct further studies and you want to be sure that you are not missing any possible exoplanets. Recall is the percentage of total exoplanets that are included, not caring about the non-exoplanets wrongly predicted.\n",
    "\n",
    "[Here is a visual of precision and recall from wikipedia](https://en.wikipedia.org/wiki/Precision_and_recall#/media/File:Precisionrecall.svg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb9f8f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4587  331]\n",
      " [ 522 1073]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91      4918\n",
      "           1       0.76      0.67      0.72      1595\n",
      "\n",
      "    accuracy                           0.87      6513\n",
      "   macro avg       0.83      0.80      0.82      6513\n",
      "weighted avg       0.87      0.87      0.87      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show confusion matrix and classification report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "model = XGBClassifier()\n",
    "model.fit(X2_train, y2_train)\n",
    "y2_pred = model.predict(X2_test)\n",
    "print(confusion_matrix(y2_test, y2_pred))\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91adc8",
   "metadata": {},
   "source": [
    "### f1-score examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12259f2",
   "metadata": {},
   "source": [
    "Let's see how to use the f1-score generally, and within cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70ff08b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7155718572857619"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the f1-score on a test set\n",
    "model = XGBClassifier()\n",
    "model.fit(X2_train, y2_train)\n",
    "y2_pred = model.predict(X2_test)\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y2_test, y2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "318715de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71910112 0.68494343 0.71667381 0.70818815 0.70639033]\n",
      "0.707059368934143\n"
     ]
    }
   ],
   "source": [
    "# show the f1-score within cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "ksfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "clf=XGBClassifier()\n",
    "scores = cross_val_score(clf, X2_train, y2_train, scoring='f1', cv=ksfold)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35d259",
   "metadata": {},
   "source": [
    "## 3.5 First Contest\n",
    "\n",
    "The following code shows all sklearn classifiers. Try some classifiers out using cross_val_score with the StratifiedKFold, as shown above, using random_state=0. The first person who can beat the default XGBClassifier score of 0.707 will receive a prize (for ODSC attendees on Tues. Oct. 30). You must use the model default parameters as we have been doing thus far. We will change parameters in the next module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61ad52d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.ensemble import BaggingClassifier\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.calibration import CalibratedClassifierCV\n",
      "from sklearn.naive_bayes import CategoricalNB\n",
      "from sklearn.multioutput import ClassifierChain\n",
      "from sklearn.naive_bayes import ComplementNB\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.dummy import DummyClassifier\n",
      "from sklearn.tree import ExtraTreeClassifier\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.gaussian_process import GaussianProcessClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.ensemble import HistGradientBoostingClassifier\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.semi_supervised import LabelPropagation\n",
      "from sklearn.semi_supervised import LabelSpreading\n",
      "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.linear_model import LogisticRegressionCV\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "from sklearn.multioutput import MultiOutputClassifier\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.neighbors import NearestCentroid\n",
      "from sklearn.svm import NuSVC\n",
      "from sklearn.multiclass import OneVsOneClassifier\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.multiclass import OutputCodeClassifier\n",
      "from sklearn.linear_model import PassiveAggressiveClassifier\n",
      "from sklearn.linear_model import Perceptron\n",
      "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
      "from sklearn.neighbors import RadiusNeighborsClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.linear_model import RidgeClassifier\n",
      "from sklearn.linear_model import RidgeClassifierCV\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.ensemble import StackingClassifier\n",
      "from sklearn.ensemble import VotingClassifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import all_estimators\n",
    "\n",
    "estimators = all_estimators(type_filter='classifier')\n",
    "for name, class_ in estimators:\n",
    "    module_name = str(class_).split(\"'\")[1].split(\".\")[1]\n",
    "    class_name = class_.__name__\n",
    "    print(f'from sklearn.{module_name} import {class_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d7e39e",
   "metadata": {},
   "source": [
    "## Enter Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc98eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try various classifiers using cv=ksfold as defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9dbd6",
   "metadata": {},
   "source": [
    "# Module 4 - Fine-tuning Models with Sklearn\n",
    "Fine-tuning models is one of the most important concepts in machine learning. Instead of using default hyperparameters, you may adjust hyperparameters to find values better suited to your data.\n",
    "\n",
    "The technical distinction between parameters and hyperparameters is as follows. Parameters are found by the model during the build-phase when it's making adjustments to fit the model to the data; the weights in Linear Regression are an example of a parameter in this sense. Hyperparameters, by contrast, are set before the model trains on the data; for example, the depth of a Decision Tree may be changed and it is set in advance of the model build-phase; it's up to the machine learning practitioner to make these adjustments.\n",
    "\n",
    "Note that hyperparameters are often shortened to parameters and it's usually clear from context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d3bcc",
   "metadata": {},
   "source": [
    "## XGBoost Hyperparameters\n",
    "\n",
    "We focus on XGBoost Hyperparameters. XGBoost is a tree ensemble meaning that it is made of many Decision Trees. \n",
    "\n",
    "Here are a list of some XGBoost hyperparameters along with their meanings and ranges:\n",
    "\n",
    "**max_depth** - depth of each tree, meaning number of times data is split before making predictions; default=6.\n",
    "\n",
    "**n_estimators** - number of trees in ensemble; default=100.\n",
    "\n",
    "**learning_rate** - shrinks tree weights in each round of boosting; default=0.3.\n",
    "\n",
    "**subsample** - percentage of training rows for each round; default=1.\n",
    "\n",
    "**colsample_bytree** - percentage of training columns for each round; default=1.\n",
    "\n",
    "**colsample_bylevel** - percentage of training columns for each depth level of tree; default=1.\n",
    "\n",
    "**colsample_bynode** - percenage of columns to evaluate splits; default=1.\n",
    "\n",
    "See the [XGBoost Parameters Documentation](https://xgboost.readthedocs.io/en/stable/parameter.html) page for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092346c",
   "metadata": {},
   "source": [
    "## 4.1 GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6001896b",
   "metadata": {},
   "source": [
    "We can try out different parameters in sklearn's GridSeachCV. Let's start by varying the depth of each tree and see what gives the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d598cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 8}\n",
      "Best score: 669.1585860647834\n"
     ]
    }
   ],
   "source": [
    "# use GridSearchCV to search grid of hyperparameters for best values\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# GridSearch uses a dictionary of parameters to find optimal values\n",
    "params = {'max_depth':[1, 2, 3, 4, 5, 6, 8, 10]}\n",
    "\n",
    "# GridSearchCV takes an ML model, the dictionary of params, and CV scoring and folds as inputs\n",
    "model = XGBRegressor()\n",
    "grid_reg = GridSearchCV(model, params, scoring='neg_mean_squared_error', cv=kfold)\n",
    "\n",
    "# you fit gridsearch on training data just like an ml model\n",
    "grid_reg.fit(X_train, y_train)\n",
    "\n",
    "# now you can access the best parameters, with the best score\n",
    "best_params = grid_reg.best_params_\n",
    "print(\"Best params:\", best_params)\n",
    "best_score = (-grid_reg.best_score_)**0.5\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae8ceff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function includes all steps in the cell above with XGBoost as the default model\n",
    "def grid_search(params, reg=XGBRegressor()):\n",
    "    grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=kfold)\n",
    "    grid_reg.fit(X_train, y_train)\n",
    "    best_params = grid_reg.best_params_\n",
    "    print(\"Best params:\", best_params)\n",
    "    best_score = (-grid_reg.best_score_)**0.5\n",
    "    print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a9d2376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method XGBModel.get_params of XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=None, reg_lambda=None, ...)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show params of model\n",
    "model.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280dc2f1",
   "metadata": {},
   "source": [
    "Now we can narrow down max_depth and combine it with n_estimators, the total number of trees in the data. When doing a grid search, all combinations of parameters will be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf564763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 8, 'n_estimators': 50}\n",
      "Best score: 669.0794021817086\n"
     ]
    }
   ],
   "source": [
    "# search 3*4=12 different combinations of parameters \n",
    "# build 12*5=60 total cv models (60*400=2400 trees in last case)  \n",
    "grid_search({'max_depth':[4, 6, 8],\n",
    "            'n_estimators':[50, 100, 200, 400]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b2616ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 1, 'max_depth': 8, 'n_estimators': 25}\n",
      "Best score: 668.4694813521713\n"
     ]
    }
   ],
   "source": [
    "# add additional params\n",
    "grid_search(params={'max_depth':[8],\n",
    "                    'colsample_bytree':[0.4, 0.6, 0.8, 1],\n",
    "                   'n_estimators':[25, 50, 100]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf9829",
   "metadata": {},
   "source": [
    "## 4.2 RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c0d43",
   "metadata": {},
   "source": [
    "It's often a good idea to start with a random search to try and find a good starting point. Instead of searching all possible options, random searches will check for 10 random combinations by default and return the hyperaparamters with the best scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5376da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV works the same way, but checks n (10 by default) random combinations\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "def random_search(params, reg=XGBRegressor()):\n",
    "    grid_reg = RandomizedSearchCV(reg, params, scoring='neg_mean_squared_error', cv=kfold, n_iter=10, random_state=0)\n",
    "    grid_reg.fit(X_train, y_train)\n",
    "    best_params = grid_reg.best_params_\n",
    "    print(\"Best params:\", best_params)\n",
    "    best_score = (-grid_reg.best_score_)**0.5\n",
    "    print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83b07f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'subsample': 0.9, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.1, 'colsample_bytree': 0.8, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.8}\n",
      "Best score: 628.7523666895315\n"
     ]
    }
   ],
   "source": [
    "# the following is a reasonable starting sample of params\n",
    "random_search(params={'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        'colsample_bynode':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        'colsample_bytree':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        'colsample_bylevel':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "        'min_child_weight':[1, 2, 3, 4, 5], \n",
    "        'learning_rate':[0.001, 0.01, 0.1, 0.2, 0.4, 0.6], \n",
    "        'max_depth':[2, 3, 4, 5, 6, 8, 10], \n",
    "        #'n_estimators':[25, 50, 100, 200, 400]\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a933403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'subsample': 1, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.7, 'colsample_bynode': 0.8, 'colsample_bylevel': 0.7}\n",
      "Best score: 626.6780890592731\n"
     ]
    }
   ],
   "source": [
    "# adjust based on results\n",
    "random_search(params={'subsample':[0.8, 0.9, 1],\n",
    "        'colsample_bynode':[0.8, 0.9, 1],\n",
    "        'colsample_bytree':[0.7, 0.8, 0.9],\n",
    "        'colsample_bylevel':[0.7, 0.8, 0.9], \n",
    "        'learning_rate':[0.05, 0.1, 0.25], \n",
    "        'max_depth':[4, 6, 8], \n",
    "        #'n_estimators':[50, 100, 200]\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "509e97b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bylevel': 0.7, 'colsample_bynode': 0.9, 'colsample_bytree': 0.9, 'learning_rate': 0.075, 'max_depth': 4, 'subsample': 0.9}\n",
      "Best score: 617.1317859597806\n"
     ]
    }
   ],
   "source": [
    "# narrow params\n",
    "grid_search(params={'subsample':[0.9],\n",
    "        'colsample_bynode':[0.9],\n",
    "        'colsample_bytree':[0.9],\n",
    "        'colsample_bylevel':[0.7], \n",
    "        'learning_rate':[0.01, 0.025, 0.05, 0.075], \n",
    "        'max_depth':[4, 6, 8],\n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1a6bc7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bylevel': 0.5, 'colsample_bynode': 0.9, 'colsample_bytree': 0.9, 'learning_rate': 0.075, 'max_depth': 4, 'n_estimators': 200, 'subsample': 0.9}\n",
      "Best score: 611.1755986598299\n"
     ]
    }
   ],
   "source": [
    "# narrow params\n",
    "grid_search(params={'subsample':[0.9],\n",
    "        'colsample_bynode':[0.9],\n",
    "        'colsample_bytree':[0.9],\n",
    "        'colsample_bylevel':[0.5, 0.6, 0.7], \n",
    "        'learning_rate':[0.075], \n",
    "        'max_depth':[4],\n",
    "        'n_estimators':[50, 100, 200, 400]\n",
    "                   })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5afe69",
   "metadata": {},
   "source": [
    "## Your turn!\n",
    "\n",
    "Try your own random and grid searches to get the best possible cv score on 5 folds using random_state=0. You may use additional params/models. Whomever gets the best score (lowest is best, since we are using RMSE) is the winner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "037b1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try your own random searches, and/or grid searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eab774",
   "metadata": {},
   "source": [
    "# Module 5 - Finalizing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbfd347",
   "metadata": {},
   "source": [
    "After selecting the hyperparameters of your best model, you can finalize the model and take advantage of additional sklearn features such as feature_importances_ to determine the most influential columns; pipelines are useful to automate the data cleaning and model-building process for future data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8bd499",
   "metadata": {},
   "source": [
    "## 5.1 Check Model on Test Data\n",
    "After finalizing a best model, you should train the model on the training data and score it against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f79ec0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628.2274646343187"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose your best model, fit on your data, then test against unseen data\n",
    "model = XGBRegressor(subsample=0.9, n_estimators=200, max_depth=4,\n",
    "                    learning_rate=0.075, colsample_bytree=0.9,\n",
    "                    colsample_bynode=0.9, colsample_bylevel=0.5)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "mse**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f3b73f",
   "metadata": {},
   "source": [
    "## 5.2 Train Model on All Data\n",
    "If your model is ready to move foward for real predictions, you should go back and train on all the data. Why? Because more data is better. At this stage you don't have to worry about overfitting. You have a model that already generalizes well to new data. You want more data for your model to learn from\n",
    "\n",
    "### Using NumPy Arrays\n",
    "\n",
    "It's often easier to make predictions from ML models when your inputs are NumPy Arrays. Then you don't have worry about column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a932476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=0.5, colsample_bynode=0.9, colsample_bytree=0.9,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.075, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=200, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert data to numpy arrays\n",
    "import numpy as np\n",
    "X_np = np.array(X)\n",
    "y_np = np.array(y)\n",
    "\n",
    "# train model on all data as numpy arrays\n",
    "model = XGBRegressor(subsample=0.9, n_estimators=200, max_depth=4,\n",
    "                    learning_rate=0.075, colsample_bytree=0.9,\n",
    "                    colsample_bynode=0.9, colsample_bylevel=0.5)\n",
    "model.fit(X_np, y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7602bf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707059</td>\n",
       "      <td>0.647959</td>\n",
       "      <td>0.561765</td>\n",
       "      <td>0.304659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season   yr  mnth  holiday  weekday  workingday  weathersit      temp  \\\n",
       "239     3.0  0.0   8.0      0.0      0.0         0.0           1  0.707059   \n",
       "\n",
       "        atemp       hum  windspeed  \n",
       "239  0.647959  0.561765   0.304659  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select last row to modify\n",
    "X_test.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48f68967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4507.306 , 4240.8145, 4947.832 ], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make some predictions\n",
    "model.predict(np.array([[3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1, 0.707059, 0.647959, 0.561765, 0.304659],\n",
    "                       [3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1, 0.757059, 0.697959, 0.561765, 0.304659],\n",
    "                       [3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1, 0.677059, 0.647959, 0.561765, 0.104659]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21843803",
   "metadata": {},
   "source": [
    "## 5.3 Saving Models with Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ede79f",
   "metadata": {},
   "source": [
    "In the event that your final model has value and will be utilized later, you may save your models and access them using pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb30217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=0.5, colsample_bynode=0.9, colsample_bytree=0.9,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.075, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=1,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=200, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
      "             reg_lambda=1, ...)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save model to local machine\n",
    "filename = 'final_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "  \n",
    "# load the model from disk\n",
    "load_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#check model\n",
    "print(load_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b732e1",
   "metadata": {},
   "source": [
    "## 5.4 Column Importance: feature_importances_\n",
    "\n",
    "We can check the overall influence of each column using feature_importances_. Whereas checking correlations of columns is useful for linear comparisons, this process gives the influence of columns for non-linear tree ensembles. \n",
    "\n",
    "You can use feature_importances_ earlier in the process to help narrow down columns as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4ed3962f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1657849 , 0.42669895, 0.06681323, 0.00972347, 0.01182685,\n",
       "       0.00876925, 0.06133859, 0.07507053, 0.12267406, 0.03070163,\n",
       "       0.02059859], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the influence of each column\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6fe5d360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yr', 0.42669895),\n",
       " ('season', 0.1657849),\n",
       " ('atemp', 0.122674055),\n",
       " ('temp', 0.07507053),\n",
       " ('mnth', 0.06681323),\n",
       " ('weathersit', 0.06133859),\n",
       " ('hum', 0.030701632),\n",
       " ('windspeed', 0.020598589),\n",
       " ('weekday', 0.011826854),\n",
       " ('holiday', 0.009723474),\n",
       " ('workingday', 0.00876925)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip columns and feature_importances_ into dict\n",
    "feature_dict = dict(zip(X.columns, model.feature_importances_))\n",
    "\n",
    "# import operator\n",
    "import operator\n",
    "\n",
    "# sort dict by values (as list of tuples)\n",
    "sorted(feature_dict.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f356f6",
   "metadata": {},
   "source": [
    "## 5.5 Pipelines\n",
    "\n",
    "Automating the process of collecting data, cleaning data, and training a machine learning model on the data may be achieved via sklearn pipelines.\n",
    "\n",
    "Clearing null values via the SimpleImputer and converting categorical columns via the OneHotEncoder are standard. You can design your own classes for more complicated procedures. (See https://github.com/PacktPublishing/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/blob/master/Chapter10/XGBoost_Model_Deployment.ipynb for examples.)\n",
    "\n",
    "The example that follows includes the SimpleImputer and the ML model in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "21f9afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline to transform data by clearing null values and fitting xgb model on data\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "full_pipeline = Pipeline([('null', SimpleImputer(missing_values=np.nan, \n",
    "                                                         strategy='median')),  \n",
    "                          ('xgb', XGBRegressor(max_depth=4,\n",
    "                                               n_estimators=200,\n",
    "                                               learning_rate=0.075,\n",
    "                                               subsample=0.9, \n",
    "                                               colsample_bytree=0.9, \n",
    "                                               colsample_bylevel=0.5,\n",
    "                                               colsample_bynode=0.9, \n",
    "                                              ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8bd5d4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('null', SimpleImputer(strategy='median')),\n",
       "                ('xgb',\n",
       "                 XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "                              colsample_bylevel=0.5, colsample_bynode=0.9,\n",
       "                              colsample_bytree=0.9, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "                              importance_type=None, interaction_constraints='',\n",
       "                              learning_rate=0.075, max_bin=256,\n",
       "                              max_cat_to_onehot=4, max_delta_step=0,\n",
       "                              max_depth=4, max_leaves=0, min_child_weight=1,\n",
       "                              missing=nan, monotone_constraints='()',\n",
       "                              n_estimators=200, n_jobs=0, num_parallel_tree=1,\n",
       "                              predictor='auto', random_state=0, reg_alpha=0,\n",
       "                              reg_lambda=1, ...))])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the pipeline on your data\n",
    "full_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "82b22193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5426.846  , 4604.4785 , 1297.9181 , 1319.1804 , 3677.2258 ,\n",
       "       1917.0964 , 3004.2808 , 6315.954  , 6653.0938 , 1216.8851 ,\n",
       "       1571.0406 , 1360.2284 , 1484.4102 , 4810.1396 , 4624.3784 ,\n",
       "       4094.9329 , 7513.7314 , 6517.717  , 3601.858  , 2005.2458 ,\n",
       "       7617.31   , 1644.6609 , 5256.659  , 4417.773  , 1723.6769 ,\n",
       "       5907.545  , 3400.5857 , 5237.753  , 7505.26   , 7921.6865 ,\n",
       "        705.01184, 5116.439  , 5973.9087 , 5296.1143 , 1956.8448 ,\n",
       "       3870.8042 , 6745.506  , 5100.06   , 2559.2012 , 3079.6116 ,\n",
       "       7032.815  , 1115.9336 , 4995.4214 , 3677.9053 , 7254.9844 ,\n",
       "       7434.9277 , 2203.2358 , 3682.1528 , 2712.967  , 1934.7947 ,\n",
       "       6108.701  , 6797.68   , 5445.376  , 7176.278  , 4119.6016 ,\n",
       "       3731.478  , 3506.8882 , 7070.639  , 6899.389  , 3600.1506 ,\n",
       "       7196.9756 , 4124.8027 , 4047.785  , 8338.744  , 7351.622  ,\n",
       "       2358.999  , 5074.493  , 5465.236  , 6748.441  , 5289.1367 ,\n",
       "       6502.138  , 7346.4478 , 4688.1553 , 6846.597  , 3723.4985 ,\n",
       "       6527.4033 , 5737.5522 , 7054.6626 , 2543.7449 , 1711.6985 ,\n",
       "       4470.8315 , 4819.0645 , 5272.357  , 1879.7122 , 4921.0083 ,\n",
       "       7500.581  , 5029.8677 , 6164.667  , 4565.4863 , 4042.0007 ,\n",
       "       1202.7374 ,  988.9414 , 6695.322  , 6765.396  , 4171.5825 ,\n",
       "       1110.4127 ,  349.33328, 7343.0073 , 4203.945  , 3567.969  ,\n",
       "       4011.6748 , 6308.048  , 4858.025  , 7543.585  , 3527.5527 ,\n",
       "       4259.2896 , 7745.9863 , 7230.442  , 5165.359  , 2332.252  ,\n",
       "       3883.4365 , 3892.626  , 3930.5237 , 1668.2408 , 1952.7258 ,\n",
       "       4747.4204 , 4765.428  , 4105.3447 , 7004.2383 , 5945.1504 ,\n",
       "       1867.0862 , 4524.9443 , 3161.0605 , 3063.6926 , 4345.3438 ,\n",
       "       4395.0205 , 1492.6974 , 6529.6646 , 3000.297  , 3672.8774 ,\n",
       "        824.66595, 5603.039  , 1541.6599 , 4189.762  , 3892.3157 ,\n",
       "       5797.5786 , 7043.322  , 4434.714  , 5035.705  , 5178.7227 ,\n",
       "       4776.502  , 4256.84   , 5604.484  , 5323.8755 , 5225.111  ,\n",
       "       8111.045  , 4507.306  ], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions from new data using your pipeline\n",
    "X_new = X_test.copy()\n",
    "full_pipeline.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d53471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
